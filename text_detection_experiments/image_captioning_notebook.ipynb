{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from os import listdir\n",
    "from pickle import dump\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "\n",
    "from pickle import load\n",
    "\n",
	"# (Jason Brownlee, 2019):\n",
    "# https://machinelearningmastery.com/develop-a-\n",
    "# deep-learning-caption-generation-model-in-python/\n",
    "\n",
    "import cv2\n",
    "\n",
    "dir_dataset = \"datasets/Flickr8k_Dataset\"\n",
    "dir_text = \"datasets/Flickr8k_text\"\n",
    "\n",
    "def load_doc(filename):\n",
    "    file = open(filename, \"r\")\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "def load_set(filename):\n",
    "    doc = load_doc(filename)\n",
    "    dataset = []\n",
    "    for line in doc.split(\"\\n\"):\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        id_ = line.split(\".\")[0]\n",
    "        dataset.append(id_)\n",
    "\n",
    "    return set(dataset)\n",
    "\n",
    "def load_descriptions(filename, dataset):\n",
    "    doc = load_doc(filename)\n",
    "    descriptions = dict()\n",
    "    for line in doc.split(\"\\n\"):\n",
    "        tokens = line.split()\n",
    "        image_id, image_desc = tokens[0], tokens[1:]\n",
    "        # skip images not in the dataset...\n",
    "        if image_id in dataset:\n",
    "            if image_id not in descriptions:\n",
    "                # empty list of descriptions for an image id\n",
    "                descriptions[image_id] = []\n",
    "\n",
    "            desc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n",
    "            descriptions[image_id].append(desc)\n",
    "\n",
    "    return descriptions\n",
    "\n",
    "def load_features(filename, dataset):    \n",
    "    all_features = load(open(filename, \"rb\"))\n",
    "    # filter features based on which ones are in the dataset\n",
    "    features = {k: all_features[k] for k in dataset}\n",
    "    return features\n",
    "\n",
    "# convert a dictionary of clean descriptions to a list of descriptions\n",
    "def to_lines(descriptions):\n",
    "    all_desc = []\n",
    "    for key in descriptions.keys():\n",
    "        [all_desc.append(d) for d in descriptions[key]]\n",
    "    return all_desc\n",
    "\n",
    "# fit a tokenizer given caption descriptions\n",
    "def create_tokenizer(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer\n",
    "\n",
    "# calculate the length of the description with the most words\n",
    "def max_length(descriptions):\n",
    "    lines = to_lines(descriptions)\n",
    "    return max(len(d.split()) for d in lines)\n",
    "\n",
    "def create_sequences(tokenizer, max_length, descriptions, photos, vocab_size):\n",
    "    X1, X2, y = [], [], []\n",
    "\n",
    "    for key, desc_list in descriptions.items():\n",
    "        for desc in desc_list:\n",
    "            seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "            for i in range(1, len(seq)):\n",
    "                input_, output_ = seq[0:i], seq[i]\n",
    "                # pad input if necessary\n",
    "                input_ = pad_sequences([input_], maxlen=max_length)[0]\n",
    "                # encode output\n",
    "                output_ = to_categorical([output_], num_classes=vocab_size)[0]\n",
    "                # store\n",
    "                X1.append(photos[key][0])\n",
    "                X2.append(input_)\n",
    "                y.append(output_)\n",
    "\n",
    "    return array(X1), array(X2), array(y)\n",
    "\n",
    "def tanti_et_al_model(vocab_size, max_length):\n",
    "    # feature extractor\n",
    "    inputs1 = Input(shape=(4096,))\n",
    "    f1 = Dropout(0.5)(inputs1)\n",
    "    f2 = Dense(256, activation=\"relu\")(f1)\n",
    "    # sequence\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    s1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    s2 = Dropout(0.5)(s1)\n",
    "    s3 = LSTM(256)(s2)\n",
    "    # decoder\n",
    "    d1 = add([f2, s3])\n",
    "    d2 = Dense(256, activation=\"relu\")(d1)\n",
    "    outputs = Dense(vocab_size, activation=\"softmax\")(d2)\n",
    "    # compile\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model\n",
    "\n",
    "descriptions_ = \"datasets/descriptions.txt\"\n",
    "\n",
    "# load training dataset (6K)\n",
    "filename = dir_text + \"/Flickr_8k.trainImages.txt\"\n",
    "train = load_set(filename)\n",
    "print('Dataset:', len(train))\n",
    "\n",
    "# descriptions\n",
    "train_descriptions = load_descriptions(descriptions_, train)\n",
    "print('Descriptions: train=', len(train_descriptions))\n",
    "\n",
    "# photo features\n",
    "train_features = load_features('datasets/features.pkl', train)\n",
    "print('Photos: train=', len(train_features))\n",
    "\n",
    "# prepare tokenizer\n",
    "tokenizer = create_tokenizer(train_descriptions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary size:', vocab_size)\n",
    "\n",
    "# all inputs have to be same length\n",
    "max_length = max_length(train_descriptions)\n",
    "\n",
    "X1train, X2train, ytrain = create_sequences(tokenizer, max_length, train_descriptions, train_features, vocab_size)\n",
    "\n",
    "# load test dataset (6K)\n",
    "filename = dir_text + \"/Flickr_8k.testImages.txt\"\n",
    "test = load_set(filename)\n",
    "\n",
    "# descriptions\n",
    "train_descriptions = load_descriptions(descriptions_, test)\n",
    "print('Descriptions: test=', len(test_descriptions))\n",
    "\n",
    "# photo features\n",
    "train_features = load_features('datasets/features.pkl', test)\n",
    "print('Photos: test=', len(test_features))\n",
    "\n",
    "X1test, X2test, ytest = create_sequences(tokenizer, max_length, test_descriptions, test_features, vocab_size)\n",
    "\n",
    "# define checkpoint callback\n",
    "filepath = \"model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "\n",
    "model.fit([X1train, X2train], ytrain, epochs=20, verbose=2, callbacks=[checkpoint], validation_data=([X1test, X2test], ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
